{
    "max_train_steps": 3000000,
    "evaluate_freq": 100000,
    "save_freq": 20,
    "policy_dist": "Gaussian",
    "batch_size": 512,
    "mini_batch_size": 64,
    "hidden_width": 64,
    "lr_a": 0.0003,
    "lr_c": 0.0003,
    "gamma": 0.99,
    "lamda": 0.95,
    "epsilon": 0.2,
    "K_epochs": 10,
    "use_adv_norm": true,
    "use_state_norm": false,
    "use_reward_norm": false,
    "use_reward_scaling": true,
    "entropy_coef": 0.01,
    "use_lr_decay": true,
    "use_grad_clip": true,
    "use_orthogonal_init": true,
    "set_adam_eps": true,
    "use_tanh": true,
    "is_run_mode": false,
    "state_dim": 6,
    "action_dim": 1,
    "max_episode_steps": 2048,
    "max_action_value": 0.785,
    "using_guidance": false,
    "check_safty": false,
    "velocity": 0.5,
    "wheel_base_length": 0.92,
    "absolute_dir": "/home/mohammad/catkin_ws/src/moving_agent/src/motion-planning/PPO"
}
